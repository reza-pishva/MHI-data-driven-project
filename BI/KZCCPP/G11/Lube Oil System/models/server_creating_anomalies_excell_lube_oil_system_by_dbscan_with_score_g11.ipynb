{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "در حال خواندن داده‌ها...\n",
      "ستون‌های سنسور: 7 تا\n",
      "اجرای DBSCAN...\n",
      "محاسبه شدت انومالی (model_value)...\n",
      "در حال ذخیره فایل کامل مدل...\n",
      "\n",
      "======================================================================\n",
      "                  نتایج نهایی مدل DBSCAN\n",
      "======================================================================\n",
      "کل رکوردها            : 10,927\n",
      "داده‌های عادی (Normal) : 10,414\n",
      "داده‌های غیرعادی (Anomaly): 513 (4.69%)\n",
      "بیشترین امتیاز انومالی: 100.0\n",
      "میانگین امتیاز انومالی در داده‌های غیرعادی: 70.5\n",
      "======================================================================\n",
      "فایل کامل مدل ذخیره شد → C:\\BI\\dbscan_model1.xlsx\n",
      "فایل فقط انومالی‌ها → C:\\BI\\lube_oil_system_anomalies_g11.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# ------------------- تنظیمات -------------------\n",
    "base_path = r\"C:\\BI\\KZCCPP\\G11\\Lube Oil System\"\n",
    "input_file = os.path.join(base_path, \"lube_oil_system_data_g11.xlsx\")\n",
    "output_anomalies = os.path.join(base_path, \"lube_oil_system_anomalies_g11.xlsx\")\n",
    "output_full_model = os.path.join(base_path, \"dbscan_model1.xlsx\")\n",
    "\n",
    "MIN_CLUSTER_SIZE = 15  # خوشه‌های کوچکتر از این → انومالی\n",
    "eps = 0.5\n",
    "min_samples = 10\n",
    "\n",
    "# ------------------- خواندن داده -------------------\n",
    "print(\"در حال خواندن داده‌ها...\")\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# ستون‌های سنسور\n",
    "sensor_columns = [col for col in df.columns if col.startswith('AssetID_') and str(col.split('_')[-1]).isdigit()]\n",
    "print(f\"ستون‌های سنسور: {len(sensor_columns)} تا\")\n",
    "\n",
    "id_columns = ['id', 'RecordDate', 'RecordTime']\n",
    "optional_cols = ['unitID', 'TimeStamps', 'created_at', 'updated_at']\n",
    "available_optional = [col for col in optional_cols if col in df.columns]\n",
    "\n",
    "# ------------------- پیش‌پردازش -------------------\n",
    "X = df[sensor_columns].copy()\n",
    "X = X.fillna(X.mean())\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ------------------- DBSCAN -------------------\n",
    "print(\"اجرای DBSCAN...\")\n",
    "db = DBSCAN(eps=eps, min_samples=min_samples, n_jobs=-1)\n",
    "labels = db.fit_predict(X_scaled)\n",
    "\n",
    "# ------------------- تحلیل خوشه‌ها -------------------\n",
    "label_counts = Counter(labels)\n",
    "large_cluster_labels = [lbl for lbl, cnt in label_counts.items() if lbl != -1 and cnt >= MIN_CLUSTER_SIZE]\n",
    "small_cluster_labels = [lbl for lbl, cnt in label_counts.items() if lbl != -1 and cnt < MIN_CLUSTER_SIZE]\n",
    "noise_mask = labels == -1\n",
    "\n",
    "# نقاط متعلق به خوشه‌های بزرگ (برای محاسبه فاصله)\n",
    "large_cluster_mask = np.isin(labels, large_cluster_labels)\n",
    "X_large = X_scaled[large_cluster_mask]\n",
    "\n",
    "# ------------------- محاسبه فاصله تا نزدیک‌ترین خوشه اصلی -------------------\n",
    "print(\"محاسبه شدت انومالی (model_value)...\")\n",
    "if len(X_large) > 0:\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(X_large)\n",
    "    distances, _ = nbrs.kneighbors(X_scaled)\n",
    "    distances = distances.flatten()\n",
    "else:\n",
    "    distances = np.zeros(len(X_scaled))  # اگر هیچ خوشه بزرگی نبود\n",
    "\n",
    "# ------------------- ساخت model_value (0 تا 100) -------------------\n",
    "anomaly_score = np.zeros(len(df))\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    if label in large_cluster_labels:\n",
    "        score = 0  # کاملاً نرمال\n",
    "    else:\n",
    "        # پایه: فاصله زیاد = امتیاز بالا\n",
    "        dist_score = min(distances[i] / (eps * 3), 1.0) * 70  # حداکثر 70 از فاصله\n",
    "        \n",
    "        if label == -1:\n",
    "            cluster_penalty = 30  # نویز خیلی غیرعادی\n",
    "        elif label in small_cluster_labels:\n",
    "            size = label_counts[label]\n",
    "            cluster_penalty = max(10, 30 - size)  # خوشه 1 نفره → 29، خوشه 14 نفره → 16\n",
    "        else:\n",
    "            cluster_penalty = 0\n",
    "        \n",
    "        score = dist_score + cluster_penalty\n",
    "        score = min(score, 100)  # حداکثر 100\n",
    "    \n",
    "    anomaly_score[i] = round(score, 2)\n",
    "\n",
    "# ------------------- ساخت دیتافریم نهایی -------------------\n",
    "result_df = df.copy()\n",
    "\n",
    "# ستون DateTime\n",
    "if 'RecordDate' in result_df.columns and 'RecordTime' in result_df.columns:\n",
    "    result_df['DateTime'] = pd.to_datetime(\n",
    "        result_df['RecordDate'].astype(str) + ' ' + result_df['RecordTime'].astype(str),\n",
    "        errors='coerce'\n",
    "    )\n",
    "else:\n",
    "    result_df['DateTime'] = pd.NaT\n",
    "\n",
    "# اضافه کردن ستون‌های مدل\n",
    "result_df['model_name'] = 'DBSCAN_Anomaly_Detection'\n",
    "result_df['model_result'] = np.where(anomaly_score == 0, 'Normal', 'Anomaly')\n",
    "result_df['model_value'] = anomaly_score\n",
    "\n",
    "# مرتب‌سازی ستون‌ها به ترتیب خواسته شده\n",
    "desired_columns = [\n",
    "    'id', 'AssetID_8341', 'AssetID_8342', 'AssetID_8343', 'AssetID_8344',\n",
    "    'AssetID_8346', 'AssetID_9286', 'AssetID_9287',\n",
    "    'unitID', 'model_name', 'model_result', 'model_value',\n",
    "    'DateTime', 'RecordDate', 'RecordTime', 'TimeStamps', 'created_at', 'updated_at'\n",
    "]\n",
    "\n",
    "# فقط ستون‌های موجود را نگه دار\n",
    "final_columns = [col for col in desired_columns if col in result_df.columns]\n",
    "# بقیه ستون‌های سنسور رو هم اضافه کن اگر نبودن\n",
    "for col in sensor_columns:\n",
    "    if col not in final_columns and col in result_df.columns:\n",
    "        final_columns.insert(final_columns.index('unitID') if 'unitID' in final_columns else 8, col)\n",
    "\n",
    "result_df = result_df[final_columns]\n",
    "\n",
    "# مرتب‌سازی بر اساس زمان\n",
    "result_df = result_df.sort_values('DateTime').reset_index(drop=True)\n",
    "\n",
    "# ------------------- ذخیره فایل کامل مدل -------------------\n",
    "print(\"در حال ذخیره فایل کامل مدل...\")\n",
    "result_df.to_excel(output_full_model, index=False)\n",
    "\n",
    "# ------------------- ذخیره فقط انومالی‌ها (مثل قبل) -------------------\n",
    "anomaly_mask_final = anomaly_score > 0\n",
    "anomalies_df = result_df[anomaly_mask_final].copy()\n",
    "anomalies_df.to_excel(output_anomalies, index=False)\n",
    "\n",
    "# ------------------- خلاصه نهایی -------------------\n",
    "n_anomalies = len(anomalies_df)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"                  نتایج نهایی مدل DBSCAN\")\n",
    "print(\"=\"*70)\n",
    "print(f\"کل رکوردها            : {len(result_df):,}\")\n",
    "print(f\"داده‌های عادی (Normal) : {len(result_df) - n_anomalies:,}\")\n",
    "print(f\"داده‌های غیرعادی (Anomaly): {n_anomalies:,} ({n_anomalies/len(result_df)*100:.2f}%)\")\n",
    "print(f\"بیشترین امتیاز انومالی: {anomaly_score.max():.1f}\")\n",
    "print(f\"میانگین امتیاز انومالی در داده‌های غیرعادی: {anomaly_score[anomaly_score > 0].mean():.1f}\")\n",
    "print(\"=\"*70)\n",
    "print(f\"فایل کامل مدل ذخیره شد → {output_full_model}\")\n",
    "print(f\"فایل فقط انومالی‌ها → {output_anomalies}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
