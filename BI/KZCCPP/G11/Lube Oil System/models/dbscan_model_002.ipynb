{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import joblib\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "df1 = pd.read_excel('output_lube_oil_g11.xlsx')\n",
        "selected_columns = ['AssetID_8341', 'AssetID_8342', 'AssetID_8343', 'AssetID_8344',\n",
        "                    'AssetID_8346', 'AssetID_9286', 'AssetID_9287']\n",
        "data_to_scale = df1[selected_columns]\n",
        "\n",
        "# استانداردسازی\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(data_to_scale)\n",
        "scaled_df = pd.DataFrame(scaled_data, columns=selected_columns)\n",
        "scaled_df_clean = scaled_df.dropna()\n",
        "\n",
        "# اجرای DBSCAN\n",
        "dbscan = DBSCAN(eps=0.7, min_samples=6)\n",
        "labels = dbscan.fit_predict(scaled_df_clean)\n",
        "\n",
        "# جدا کردن داده‌های نویز و خوشه‌ها\n",
        "df = scaled_df_clean.copy()\n",
        "df['label'] = labels\n",
        "noise_mask = df['label'] == -1\n",
        "cluster_mask = df['label'] != -1\n",
        "noise_points = df[noise_mask].drop(columns='label').values\n",
        "cluster_points = df[cluster_mask].drop(columns='label').values\n",
        "\n",
        "# محاسبه فاصله و وزن ناهنجاری\n",
        "distances = pairwise_distances(noise_points, cluster_points)\n",
        "min_distances = distances.min(axis=1)\n",
        "normalized_weights = (min_distances - min_distances.min()) / (min_distances.max() - min_distances.min())\n",
        "\n",
        "# ساخت بردار وزن ناهنجاری\n",
        "anomaly_weights = np.zeros(len(df))\n",
        "anomaly_weights[noise_mask.values] = normalized_weights\n",
        "df['anomaly_weight'] = anomaly_weights\n",
        "\n",
        "# ذخیره مدل‌ها و داده‌های مرجع\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "joblib.dump(dbscan, 'dbscan_model.pkl')\n",
        "np.save('cluster_points.npy', cluster_points)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNoPLuTiZUWUEexFNo4F773",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "test2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
