{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import shap\n",
    "# from xgboost import XGBRegressor\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import os\n",
    "# from datetime import datetime\n",
    "\n",
    "# # ================================\n",
    "# # مسیرها\n",
    "# # ================================\n",
    "# SHAP_OUTPUT_FILE = r\"C:\\BI\\shap_feature_importance_windows_8341_g11.xlsx\"\n",
    "# LOG_FILE = r\"C:\\BI\\regression_assetid_8341_log.txt\"\n",
    "# INPUT_FILE = r\"C:\\BI\\lube_oil_system_data_g11.xlsx\"\n",
    "# os.makedirs(r\"C:\\BI\", exist_ok=True)\n",
    "\n",
    "# def log(msg):\n",
    "#     print(msg)\n",
    "#     with open(LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "#         f.write(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}\\n\")\n",
    "\n",
    "# log(\"شروع اجرای مدل و محاسبه اهمیت فیچرها (فقط خروجی SHAP)\")\n",
    "\n",
    "# # ================================\n",
    "# # خواندن داده\n",
    "# # ================================\n",
    "# df = pd.read_excel(INPUT_FILE)\n",
    "# log(f\"داده خوانده شد → {len(df):,} ردیف\")\n",
    "\n",
    "# # ================================\n",
    "# # ساخت datetime\n",
    "# # ================================\n",
    "# df[\"datetime\"] = pd.to_datetime(df[\"RecordDate\"] + \" \" + df[\"RecordTime\"], errors=\"coerce\")\n",
    "# df = df.sort_values(\"datetime\").reset_index(drop=True)\n",
    "\n",
    "# # ================================\n",
    "# # mapping اسامی خوانا (اینجا اضافه شد)\n",
    "# # ================================\n",
    "# friendly_names = {\n",
    "#     \"AssetID_8341\": \"Lube oil filter diffrential pressure\",  # اگر هدف هم بخوای تغییر نام بدی\n",
    "#     \"AssetID_8342\": \"Lube oil tank level\",\n",
    "#     \"AssetID_8343\": \"Lube oil tank temperature\",\n",
    "#     \"AssetID_8344\": \"Lube oil tank vapor pressure\",\n",
    "#     \"AssetID_8346\": \"Over speed pressure\",\n",
    "#     \"AssetID_9286\": \"Main lube oil pump press\",\n",
    "#     \"AssetID_9287\": \"Lube oil line pressure\",\n",
    "#     # اگر AssetID های دیگری هم داری، همین‌جا اضافه کن\n",
    "# }\n",
    "\n",
    "# # جایگزینی نام ستون‌ها در دیتافریم اصلی\n",
    "# df.rename(columns=friendly_names, inplace=True)\n",
    "\n",
    "# # ================================\n",
    "# # آماده‌سازی داده‌ها\n",
    "# # ================================\n",
    "# TARGET_COL = \"Target (Lube Oil Parameter)\"   # نام جدید هدف\n",
    "# feature_cols = [c for c in df.columns if c not in ['id', 'RecordDate', 'RecordTime', 'datetime', TARGET_COL]]\n",
    "# X = df[feature_cols]\n",
    "# y = df[TARGET_COL]\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "# X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X_scaled, y, test_size=0.2, shuffle=False\n",
    "# )\n",
    "\n",
    "# # ================================\n",
    "# # مدل\n",
    "# # ================================\n",
    "# model = XGBRegressor(\n",
    "#     n_estimators=800,\n",
    "#     learning_rate=0.03,\n",
    "#     max_depth=7,\n",
    "#     subsample=0.9,\n",
    "#     colsample_bytree=0.8,\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# model.fit(X_train, y_train)\n",
    "# log(\"مدل آموزش دید\")\n",
    "\n",
    "# # ================================\n",
    "# # محاسبه SHAP\n",
    "# # ================================\n",
    "# explainer = shap.TreeExplainer(model)\n",
    "# shap_values = explainer.shap_values(X_scaled_df)\n",
    "\n",
    "# # ساخت دیتافریم SHAP با نام‌های خوانا\n",
    "# shap_df = pd.DataFrame(shap_values, columns=X.columns)   # اینجا دیگر نام‌ها خوانا هستند\n",
    "# shap_df[\"datetime\"] = df[\"datetime\"]\n",
    "\n",
    "# # ================================\n",
    "# # تابع محاسبه اهمیت فیچر\n",
    "# # ================================\n",
    "# def compute_importance(window_df):\n",
    "#     if len(window_df) == 0:\n",
    "#         return []\n",
    "#     imp = window_df.abs().mean().sort_values(ascending=False)\n",
    "#     return list(imp.index)\n",
    "\n",
    "# # ================================\n",
    "# # تعیین پنجره‌ها\n",
    "# # ================================\n",
    "# end_date = df[\"datetime\"].max()\n",
    "# windows = {\n",
    "#     \"10_days\": (end_date - pd.Timedelta(days=10), end_date),\n",
    "#     \"10_to_20_days\": (end_date - pd.Timedelta(days=20), end_date - pd.Timedelta(days=10)),\n",
    "#     \"20_to_30_days\": (end_date - pd.Timedelta(days=30), end_date - pd.Timedelta(days=20)),\n",
    "#     \"1_month\": (end_date - pd.DateOffset(months=1), end_date),\n",
    "#     \"2_month\": (end_date - pd.DateOffset(months=2), end_date - pd.DateOffset(months=1)),\n",
    "#     \"3_month\": (end_date - pd.DateOffset(months=3), end_date - pd.DateOffset(months=2)),\n",
    "# }\n",
    "\n",
    "# # ================================\n",
    "# # محاسبه اهمیت در هر پنجره\n",
    "# # ================================\n",
    "# importance_table = {}\n",
    "# for key, (start, end) in windows.items():\n",
    "#     win = shap_df[(shap_df[\"datetime\"] >= start) & (shap_df[\"datetime\"] <= end)]\n",
    "#     win = win.drop(columns=[\"datetime\"])\n",
    "#     importance_table[key] = compute_importance(win)\n",
    "\n",
    "# max_len = max(len(v) for v in importance_table.values() if v)  # جلوگیری از خطا اگر پنجره خالی باشد\n",
    "\n",
    "# # ================================\n",
    "# # ساخت جدول خروجی 6 ستونه با نام‌های خوانا\n",
    "# # ================================\n",
    "# output_table = pd.DataFrame({\n",
    "#     \"Top Features - Last 10 Days\": importance_table[\"10_days\"] + [\"\"] * (max_len - len(importance_table[\"10_days\"])),\n",
    "#     \"Top Features - 10-20 Days Ago\": importance_table[\"10_to_20_days\"] + [\"\"] * (max_len - len(importance_table[\"10_to_20_days\"])),\n",
    "#     \"Top Features - 20-30 Days Ago\": importance_table[\"20_to_30_days\"] + [\"\"] * (max_len - len(importance_table[\"20_to_30_days\"])),\n",
    "#     \"Top Features - Last 1 Month\": importance_table[\"1_month\"] + [\"\"] * (max_len - len(importance_table[\"1_month\"])),\n",
    "#     \"Top Features - Last 2 Months\": importance_table[\"2_month\"] + [\"\"] * (max_len - len(importance_table[\"2_month\"])),\n",
    "#     \"Top Features - Last 3 Months\": importance_table[\"3_month\"] + [\"\"] * (max_len - len(importance_table[\"3_month\"])),\n",
    "# })\n",
    "\n",
    "# # ================================\n",
    "# # ذخیره خروجی\n",
    "# # ================================\n",
    "# output_table.to_excel(SHAP_OUTPUT_FILE, index=False)\n",
    "# log(\"فایل SHAP با نام‌های خوانا و 6 ستون ساخته شد\")\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"SHAP feature importance با نام‌های خوانا ساخته شد!\")\n",
    "# print(\"ذخیره شده در:\", SHAP_OUTPUT_FILE)\n",
    "# print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "شروع اجرای مدل و محاسبه اهمیت فیچرها (فقط خروجی SHAP)\n",
      "داده خوانده شد → 10,927 ردیف\n",
      "مدل آموزش دید\n",
      "فایل SHAP با نام‌های خوانا و 6 ستون ساخته شد\n",
      "\n",
      "================================================================================\n",
      "SHAP feature importance با نام‌های خوانا ساخته شد!\n",
      "ذخیره شده در: C:\\BI\\shap_feature_importance_windows_9286_g11.xlsx\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import shap\n",
    "# from xgboost import XGBRegressor\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import os\n",
    "# from datetime import datetime\n",
    "\n",
    "# # ================================\n",
    "# # مسیرها\n",
    "# # ================================\n",
    "# SHAP_OUTPUT_FILE = r\"C:\\BI\\shap_feature_importance_windows_9286_g11.xlsx\"\n",
    "# LOG_FILE = r\"C:\\BI\\regression_assetid_9286_log.txt\"\n",
    "# INPUT_FILE = r\"C:\\BI\\lube_oil_system_data_g11.xlsx\"\n",
    "# os.makedirs(r\"C:\\BI\", exist_ok=True)\n",
    "\n",
    "# def log(msg):\n",
    "#     print(msg)\n",
    "#     with open(LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "#         f.write(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}\\n\")\n",
    "\n",
    "# log(\"شروع اجرای مدل و محاسبه اهمیت فیچرها (فقط خروجی SHAP)\")\n",
    "\n",
    "# # ================================\n",
    "# # خواندن داده\n",
    "# # ================================\n",
    "# df = pd.read_excel(INPUT_FILE)\n",
    "# log(f\"داده خوانده شد → {len(df):,} ردیف\")\n",
    "\n",
    "# # ================================\n",
    "# # ساخت datetime\n",
    "# # ================================\n",
    "# df[\"datetime\"] = pd.to_datetime(df[\"RecordDate\"] + \" \" + df[\"RecordTime\"], errors=\"coerce\")\n",
    "# df = df.sort_values(\"datetime\").reset_index(drop=True)\n",
    "\n",
    "# # ================================\n",
    "# # mapping اسامی خوانا\n",
    "# # ================================\n",
    "# friendly_names = {\n",
    "#     \"AssetID_8341\": \"Lube oil filter diffrential pressure\",\n",
    "#     \"AssetID_8342\": \"Lube oil tank level\",\n",
    "#     \"AssetID_8343\": \"Lube oil tank temperature\",\n",
    "#     \"AssetID_8344\": \"Lube oil tank vapor pressure\",\n",
    "#     \"AssetID_8346\": \"Over speed pressure\",\n",
    "#     \"AssetID_9286\": \"Main lube oil pump press\",   # هدف جدید\n",
    "#     \"AssetID_9287\": \"Lube oil line pressure\",\n",
    "# }\n",
    "# df.rename(columns=friendly_names, inplace=True)\n",
    "\n",
    "# # ================================\n",
    "# # آماده‌سازی داده‌ها\n",
    "# # ================================\n",
    "# TARGET_COL = \"Main lube oil pump press\"   # تغییر هدف\n",
    "\n",
    "# # جایگزینی NaN و Inf در کل دیتافریم\n",
    "# df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# # حذف ردیف‌هایی که Target خالی یا NaN دارند\n",
    "# df = df.dropna(subset=[TARGET_COL])\n",
    "\n",
    "# feature_cols = [c for c in df.columns if c not in ['id', 'RecordDate', 'RecordTime', 'datetime', TARGET_COL]]\n",
    "# X = df[feature_cols].fillna(0)   # فیچرها رو هم پر می‌کنیم\n",
    "# y = df[TARGET_COL]\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "# X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X_scaled, y, test_size=0.2, shuffle=False\n",
    "# )\n",
    "\n",
    "# # ================================\n",
    "# # مدل\n",
    "# # ================================\n",
    "# model = XGBRegressor(\n",
    "#     n_estimators=800,\n",
    "#     learning_rate=0.03,\n",
    "#     max_depth=7,\n",
    "#     subsample=0.9,\n",
    "#     colsample_bytree=0.8,\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# model.fit(X_train, y_train)\n",
    "# log(\"مدل آموزش دید\")\n",
    "\n",
    "# # ================================\n",
    "# # محاسبه SHAP\n",
    "# # ================================\n",
    "# explainer = shap.TreeExplainer(model)\n",
    "# shap_values = explainer.shap_values(X_scaled_df)\n",
    "\n",
    "# shap_df = pd.DataFrame(shap_values, columns=X.columns)\n",
    "# shap_df[\"datetime\"] = df[\"datetime\"]\n",
    "\n",
    "# # ================================\n",
    "# # تابع محاسبه اهمیت فیچر\n",
    "# # ================================\n",
    "# def compute_importance(window_df):\n",
    "#     if len(window_df) == 0:\n",
    "#         return []\n",
    "#     imp = window_df.abs().mean().sort_values(ascending=False)\n",
    "#     return list(imp.index)\n",
    "\n",
    "# # ================================\n",
    "# # تعیین پنجره‌ها\n",
    "# # ================================\n",
    "# end_date = df[\"datetime\"].max()\n",
    "# windows = {\n",
    "#     \"10_days\": (end_date - pd.Timedelta(days=10), end_date),\n",
    "#     \"10_to_20_days\": (end_date - pd.Timedelta(days=20), end_date - pd.Timedelta(days=10)),\n",
    "#     \"20_to_30_days\": (end_date - pd.Timedelta(days=30), end_date - pd.Timedelta(days=20)),\n",
    "#     \"1_month\": (end_date - pd.DateOffset(months=1), end_date),\n",
    "#     \"2_month\": (end_date - pd.DateOffset(months=2), end_date - pd.DateOffset(months=1)),\n",
    "#     \"3_month\": (end_date - pd.DateOffset(months=3), end_date - pd.DateOffset(months=2)),\n",
    "# }\n",
    "\n",
    "# # ================================\n",
    "# # محاسبه اهمیت در هر پنجره\n",
    "# # ================================\n",
    "# importance_table = {}\n",
    "# for key, (start, end) in windows.items():\n",
    "#     win = shap_df[(shap_df[\"datetime\"] >= start) & (shap_df[\"datetime\"] <= end)]\n",
    "#     win = win.drop(columns=[\"datetime\"])\n",
    "#     importance_table[key] = compute_importance(win)\n",
    "\n",
    "# max_len = max(len(v) for v in importance_table.values() if v)\n",
    "\n",
    "# # ================================\n",
    "# # ساخت جدول خروجی 6 ستونه\n",
    "# # ================================\n",
    "# output_table = pd.DataFrame({\n",
    "#     \"Top Features - Last 10 Days\": importance_table[\"10_days\"] + [\"\"] * (max_len - len(importance_table[\"10_days\"])),\n",
    "#     \"Top Features - 10-20 Days Ago\": importance_table[\"10_to_20_days\"] + [\"\"] * (max_len - len(importance_table[\"10_to_20_days\"])),\n",
    "#     \"Top Features - 20-30 Days Ago\": importance_table[\"20_to_30_days\"] + [\"\"] * (max_len - len(importance_table[\"20_to_30_days\"])),\n",
    "#     \"Top Features - Last 1 Month\": importance_table[\"1_month\"] + [\"\"] * (max_len - len(importance_table[\"1_month\"])),\n",
    "#     \"Top Features - Last 2 Months\": importance_table[\"2_month\"] + [\"\"] * (max_len - len(importance_table[\"2_month\"])),\n",
    "#     \"Top Features - Last 3 Months\": importance_table[\"3_month\"] + [\"\"] * (max_len - len(importance_table[\"3_month\"])),\n",
    "# })\n",
    "\n",
    "# # ================================\n",
    "# # ذخیره خروجی\n",
    "# # ================================\n",
    "# output_table.to_excel(SHAP_OUTPUT_FILE, index=False)\n",
    "# log(\"فایل SHAP با نام‌های خوانا و 6 ستون ساخته شد\")\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"SHAP feature importance با نام‌های خوانا ساخته شد!\")\n",
    "# print(\"ذخیره شده در:\", SHAP_OUTPUT_FILE)\n",
    "# print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "شروع اجرای مدل و محاسبه اهمیت فیچرها (فقط خروجی SHAP)\n",
      "داده خوانده شد → 10,927 ردیف\n",
      "مدل آموزش دید\n",
      "فایل SHAP با نام‌های خوانا و 6 ستون + وزن ساخته شد\n",
      "\n",
      "================================================================================\n",
      "SHAP feature importance با نام‌های خوانا و وزن ساخته شد!\n",
      "ذخیره شده در: C:\\BI\\shap_feature_importance_windows_9286_g11.xlsx\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# ================================\n",
    "# مسیرها\n",
    "# ================================\n",
    "SHAP_OUTPUT_FILE = r\"C:\\BI\\shap_feature_importance_windows_9286_g11.xlsx\"\n",
    "LOG_FILE = r\"C:\\BI\\regression_assetid_9286_log.txt\"\n",
    "INPUT_FILE = r\"C:\\BI\\lube_oil_system_data_g11.xlsx\"\n",
    "os.makedirs(r\"C:\\BI\", exist_ok=True)\n",
    "\n",
    "def log(msg):\n",
    "    print(msg)\n",
    "    with open(LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}\\n\")\n",
    "\n",
    "log(\"شروع اجرای مدل و محاسبه اهمیت فیچرها (فقط خروجی SHAP)\")\n",
    "\n",
    "# ================================\n",
    "# خواندن داده\n",
    "# ================================\n",
    "df = pd.read_excel(INPUT_FILE)\n",
    "log(f\"داده خوانده شد → {len(df):,} ردیف\")\n",
    "\n",
    "# ================================\n",
    "# ساخت datetime\n",
    "# ================================\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"RecordDate\"] + \" \" + df[\"RecordTime\"], errors=\"coerce\")\n",
    "df = df.sort_values(\"datetime\").reset_index(drop=True)\n",
    "\n",
    "# ================================\n",
    "# mapping اسامی خوانا\n",
    "# ================================\n",
    "friendly_names = {\n",
    "    \"AssetID_8341\": \"Lube oil filter diffrential pressure\",\n",
    "    \"AssetID_8342\": \"Lube oil tank level\",\n",
    "    \"AssetID_8343\": \"Lube oil tank temperature\",\n",
    "    \"AssetID_8344\": \"Lube oil tank vapor pressure\",\n",
    "    \"AssetID_8346\": \"Over speed pressure\",\n",
    "    \"AssetID_9286\": \"Main lube oil pump press\",   # هدف جدید\n",
    "    \"AssetID_9287\": \"Lube oil line pressure\",\n",
    "}\n",
    "df.rename(columns=friendly_names, inplace=True)\n",
    "\n",
    "# ================================\n",
    "# آماده‌سازی داده‌ها\n",
    "# ================================\n",
    "TARGET_COL = \"Main lube oil pump press\"\n",
    "\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna(subset=[TARGET_COL])\n",
    "\n",
    "feature_cols = [c for c in df.columns if c not in ['id', 'RecordDate', 'RecordTime', 'datetime', TARGET_COL]]\n",
    "X = df[feature_cols].fillna(0)\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# مدل\n",
    "# ================================\n",
    "model = XGBRegressor(\n",
    "    n_estimators=800,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=7,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "log(\"مدل آموزش دید\")\n",
    "\n",
    "# ================================\n",
    "# محاسبه SHAP\n",
    "# ================================\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_scaled_df)\n",
    "\n",
    "shap_df = pd.DataFrame(shap_values, columns=X.columns)\n",
    "shap_df[\"datetime\"] = df[\"datetime\"]\n",
    "\n",
    "# ================================\n",
    "# تابع محاسبه اهمیت فیچر + وزن\n",
    "# ================================\n",
    "def compute_importance(window_df):\n",
    "    if len(window_df) == 0:\n",
    "        return [], []\n",
    "    imp = window_df.abs().mean().sort_values(ascending=False)\n",
    "    return list(imp.index), list(imp.values)\n",
    "\n",
    "# ================================\n",
    "# تعیین پنجره‌ها\n",
    "# ================================\n",
    "end_date = df[\"datetime\"].max()\n",
    "windows = {\n",
    "    \"10_days\": (end_date - pd.Timedelta(days=10), end_date),\n",
    "    \"10_to_20_days\": (end_date - pd.Timedelta(days=20), end_date - pd.Timedelta(days=10)),\n",
    "    \"20_to_30_days\": (end_date - pd.Timedelta(days=30), end_date - pd.Timedelta(days=20)),\n",
    "    \"1_month\": (end_date - pd.DateOffset(months=1), end_date),\n",
    "    \"2_month\": (end_date - pd.DateOffset(months=2), end_date - pd.DateOffset(months=1)),\n",
    "    \"3_month\": (end_date - pd.DateOffset(months=3), end_date - pd.DateOffset(months=2)),\n",
    "}\n",
    "\n",
    "# ================================\n",
    "# محاسبه اهمیت در هر پنجره\n",
    "# ================================\n",
    "importance_table = {}\n",
    "for key, (start, end) in windows.items():\n",
    "    win = shap_df[(shap_df[\"datetime\"] >= start) & (shap_df[\"datetime\"] <= end)]\n",
    "    win = win.drop(columns=[\"datetime\"])\n",
    "    feats, weights = compute_importance(win)\n",
    "    importance_table[key] = (feats, weights)\n",
    "\n",
    "max_len = max(len(v[0]) for v in importance_table.values() if v[0])\n",
    "\n",
    "# ================================\n",
    "# ساخت جدول خروجی 6 ستونه + وزن‌ها\n",
    "# ================================\n",
    "output_table = pd.DataFrame({\n",
    "    \"Top Features - Last 10 Days\": importance_table[\"10_days\"][0] + [\"\"] * (max_len - len(importance_table[\"10_days\"][0])),\n",
    "    \"Weights - Last 10 Days\": importance_table[\"10_days\"][1] + [\"\"] * (max_len - len(importance_table[\"10_days\"][1])),\n",
    "    \"Top Features - 10-20 Days Ago\": importance_table[\"10_to_20_days\"][0] + [\"\"] * (max_len - len(importance_table[\"10_to_20_days\"][0])),\n",
    "    \"Weights - 10-20 Days Ago\": importance_table[\"10_to_20_days\"][1] + [\"\"] * (max_len - len(importance_table[\"10_to_20_days\"][1])),\n",
    "    \"Top Features - 20-30 Days Ago\": importance_table[\"20_to_30_days\"][0] + [\"\"] * (max_len - len(importance_table[\"20_to_30_days\"][0])),\n",
    "    \"Weights - 20-30 Days Ago\": importance_table[\"20_to_30_days\"][1] + [\"\"] * (max_len - len(importance_table[\"20_to_30_days\"][1])),\n",
    "    \"Top Features - Last 1 Month\": importance_table[\"1_month\"][0] + [\"\"] * (max_len - len(importance_table[\"1_month\"][0])),\n",
    "    \"Weights - Last 1 Month\": importance_table[\"1_month\"][1] + [\"\"] * (max_len - len(importance_table[\"1_month\"][1])),\n",
    "    \"Top Features - Last 2 Months\": importance_table[\"2_month\"][0] + [\"\"] * (max_len - len(importance_table[\"2_month\"][0])),\n",
    "    \"Weights - Last 2 Months\": importance_table[\"2_month\"][1] + [\"\"] * (max_len - len(importance_table[\"2_month\"][1])),\n",
    "    \"Top Features - Last 3 Months\": importance_table[\"3_month\"][0] + [\"\"] * (max_len - len(importance_table[\"3_month\"][0])),\n",
    "    \"Weights - Last 3 Months\": importance_table[\"3_month\"][1] + [\"\"] * (max_len - len(importance_table[\"3_month\"][1])),\n",
    "})\n",
    "\n",
    "# ================================\n",
    "# ذخیره خروجی\n",
    "# ================================\n",
    "output_table.to_excel(SHAP_OUTPUT_FILE, index=False)\n",
    "log(\"فایل SHAP با نام‌های خوانا و 6 ستون + وزن ساخته شد\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SHAP feature importance با نام‌های خوانا و وزن ساخته شد!\")\n",
    "print(\"ذخیره شده در:\", SHAP_OUTPUT_FILE)\n",
    "print(\"=\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
