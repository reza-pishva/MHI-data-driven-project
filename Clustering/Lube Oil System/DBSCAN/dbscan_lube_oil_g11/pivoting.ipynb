{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„\n",
    "# df = pd.read_csv('gen_brg_vib.csv')\n",
    "\n",
    "# # Ù„ÛŒØ³Øª AssetIDÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±\n",
    "# asset_ids = [9362, 9363, 9364, 9365, 9366, 9367, 9371, 9372]\n",
    "\n",
    "# # Ù„ÛŒØ³Øª Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±\n",
    "# columns = ['Value', 'RecordTime', 'RecordDate', 'DateTime', 'TimeStamp']\n",
    "\n",
    "# # Ù„ÛŒØ³Øª Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡\n",
    "# dfs = []\n",
    "\n",
    "# # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ø± AssetID Ø¨Ù‡â€ŒØµÙˆØ±Øª Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡\n",
    "# for aid in asset_ids:\n",
    "#     df_aid = df[df['AssetID'] == aid][columns].copy()\n",
    "#     df_aid.columns = [f\"{col}_{aid}\" for col in columns]\n",
    "#     dfs.append(df_aid.reset_index(drop=True))\n",
    "\n",
    "# # ØªØ±Ú©ÛŒØ¨ Ù‡Ù…Ù‡ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…â€ŒÙ‡Ø§ Ø¯Ø± Ù…Ø­ÙˆØ± Ø§ÙÙ‚ÛŒ\n",
    "# df_final = pd.concat(dfs, axis=1)\n",
    "\n",
    "# # Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ\n",
    "# df_final.to_csv('flattened_by_assetid.csv', index=False)\n",
    "\n",
    "# print(\"âœ… ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± AssetID Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: flattened_by_assetid.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ Ù‚Ø¨Ù„ÛŒ\n",
    "# df = pd.read_csv('flattened_by_assetid.csv')\n",
    "\n",
    "# # Ù„ÛŒØ³Øª AssetIDÙ‡Ø§\n",
    "# asset_ids = [9362, 9363, 9364, 9365, 9366, 9367, 9371, 9372]\n",
    "\n",
    "# # Ù„ÛŒØ³Øª Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ\n",
    "# final_rows = []\n",
    "\n",
    "# # ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§\n",
    "# n = len(df)\n",
    "\n",
    "# # Ù¾ÛŒÙ…Ø§ÛŒØ´ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§\n",
    "# for i in range(n):\n",
    "#     row = df.iloc[i]\n",
    "#     base_values = {}\n",
    "#     valid = True\n",
    "\n",
    "#     for aid in asset_ids:\n",
    "#         base_ts = row[f'TimeStamp_{aid}']\n",
    "#         if pd.isna(base_ts):\n",
    "#             valid = False\n",
    "#             break\n",
    "\n",
    "#         # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø¹Ø¯Ø¯ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø®ØªÙ„Ø§Ù\n",
    "#         try:\n",
    "#             base_ts = float(base_ts)\n",
    "#         except:\n",
    "#             valid = False\n",
    "#             break\n",
    "\n",
    "#         # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† TimeStamp Ø¯Ø± 5 Ø±Ø¯ÛŒÙ Ø¨Ø¹Ø¯ÛŒ\n",
    "#         min_diff = float('inf')\n",
    "#         closest_value = None\n",
    "\n",
    "#         for j in range(i+1, min(i+6, n)):\n",
    "#             next_ts = df.iloc[j][f'TimeStamp_{aid}']\n",
    "#             if pd.isna(next_ts):\n",
    "#                 continue\n",
    "#             try:\n",
    "#                 next_ts = float(next_ts)\n",
    "#             except:\n",
    "#                 continue\n",
    "\n",
    "#             diff = abs(next_ts - base_ts)\n",
    "#             if diff < 15000 and diff < min_diff:\n",
    "#                 min_diff = diff\n",
    "#                 closest_value = df.iloc[j][f'Value_{aid}']\n",
    "\n",
    "#         if closest_value is not None:\n",
    "#             base_values[f'Value_{aid}'] = closest_value\n",
    "#         else:\n",
    "#             valid = False\n",
    "#             break\n",
    "\n",
    "#     if valid:\n",
    "#         # Ø°Ø®ÛŒØ±Ù‡ TimeStamp Ø¹Ø¯Ø¯ÛŒ\n",
    "#         base_values['BaseTimeStamp'] = base_ts\n",
    "#         # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ datetime Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø³ØªÙˆÙ† Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡\n",
    "#         base_values['BaseDateTime'] = pd.to_datetime(base_ts, unit='s')\n",
    "#         final_rows.append(base_values)\n",
    "\n",
    "# # Ø³Ø§Ø®Øª Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ù†Ù‡Ø§ÛŒÛŒ\n",
    "# df_final = pd.DataFrame(final_rows)\n",
    "\n",
    "# # Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ\n",
    "# df_final.to_csv('matched_values_with_datetime.csv', index=False)\n",
    "\n",
    "# print(\"âœ… ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ø³ØªÙˆÙ† datetime Ù‚Ø§Ø¨Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± ØªØ§ÛŒÙ…â€ŒØ³Ø±ÛŒØ² Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: matched_values_with_datetime.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ Ù‚Ø¨Ù„ÛŒ\n",
    "# df = pd.read_csv('flattened_by_assetid.csv')\n",
    "\n",
    "# # Ù„ÛŒØ³Øª AssetIDÙ‡Ø§\n",
    "# asset_ids = [9362, 9363, 9364, 9365, 9366, 9367, 9371, 9372]\n",
    "\n",
    "# # Ù„ÛŒØ³Øª Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ\n",
    "# final_rows = []\n",
    "\n",
    "# # ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§\n",
    "# n = len(df)\n",
    "\n",
    "# # Ù¾ÛŒÙ…Ø§ÛŒØ´ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§\n",
    "# for i in range(n):\n",
    "#     row = df.iloc[i]\n",
    "#     base_values = {}\n",
    "#     valid = True\n",
    "\n",
    "#     for aid in asset_ids:\n",
    "#         base_ts = row[f'TimeStamp_{aid}']\n",
    "#         if pd.isna(base_ts):\n",
    "#             valid = False\n",
    "#             break\n",
    "\n",
    "#         # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø¹Ø¯Ø¯ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø®ØªÙ„Ø§Ù\n",
    "#         try:\n",
    "#             base_ts = float(base_ts)\n",
    "#         except:\n",
    "#             valid = False\n",
    "#             break\n",
    "\n",
    "#         # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† TimeStamp Ø¯Ø± 5 Ø±Ø¯ÛŒÙ Ø¨Ø¹Ø¯ÛŒ\n",
    "#         min_diff = float('inf')\n",
    "#         closest_value = None\n",
    "#         matched_ts = None\n",
    "\n",
    "#         for j in range(i+1, min(i+6, n)):\n",
    "#             next_ts = df.iloc[j][f'TimeStamp_{aid}']\n",
    "#             if pd.isna(next_ts):\n",
    "#                 continue\n",
    "#             try:\n",
    "#                 next_ts = float(next_ts)\n",
    "#             except:\n",
    "#                 continue\n",
    "\n",
    "#             diff = abs(next_ts - base_ts)\n",
    "#             if diff < 3600 and diff < min_diff:\n",
    "#                 min_diff = diff\n",
    "#                 closest_value = df.iloc[j][f'Value_{aid}']\n",
    "#                 matched_ts = next_ts\n",
    "\n",
    "#         if closest_value is not None and matched_ts is not None:\n",
    "#             base_values[f'Value_{aid}'] = closest_value\n",
    "#             base_values[f'MatchedTimeStamp_{aid}'] = pd.to_datetime(matched_ts, unit='s')\n",
    "#         else:\n",
    "#             valid = False\n",
    "#             break\n",
    "\n",
    "#     if valid:\n",
    "#         base_values['BaseTimeStamp'] = base_ts\n",
    "#         base_values['BaseDateTime'] = pd.to_datetime(base_ts, unit='s')\n",
    "#         final_rows.append(base_values)\n",
    "\n",
    "# # Ø³Ø§Ø®Øª Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ù†Ù‡Ø§ÛŒÛŒ\n",
    "# df_final = pd.DataFrame(final_rows)\n",
    "\n",
    "# # Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ\n",
    "# df_final.to_csv('matched_values_with_timestamps.csv', index=False)\n",
    "\n",
    "# print(\"âœ… ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ù…Ù‚Ø§Ø¯ÛŒØ± Value Ùˆ TimeStampÙ‡Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚â€ŒÛŒØ§ÙØªÙ‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: matched_values_with_timestamps.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Ù…Ø±Ø­Ù„Ù‡ 1: Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ CSV\n",
    "# df = pd.read_csv('gen_brg_vib.csv')\n",
    "\n",
    "# # Ù…Ø±Ø­Ù„Ù‡ 2: Ø§Ø³ØªØ®Ø±Ø§Ø¬ AssetIDÙ‡Ø§ÛŒ ÛŒÚ©ØªØ§\n",
    "# unique_ids = df['AssetID'].unique().tolist()\n",
    "\n",
    "# # Ù…Ø±Ø­Ù„Ù‡ 3: Ø³Ø§Ø®Øª Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø®Ø±ÙˆØ¬ÛŒ\n",
    "# columns = ['TimeStamp'] + [f'AssetID_{uid}' for uid in unique_ids]\n",
    "# output_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# # Ù…Ø±Ø­Ù„Ù‡ 4 ØªØ§ 8: Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÚ©Ø±Ø§Ø±ÛŒ\n",
    "# while not df.empty and unique_ids:\n",
    "#     main_id = unique_ids[0]\n",
    "#     main_subset = df[df['AssetID'] == main_id]\n",
    "\n",
    "#     if main_subset.empty:\n",
    "#         # Ø§Ú¯Ø± Ù‡ÛŒÚ† Ø±Ø¯ÛŒÙÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† AssetID Ù†Ø¨ÙˆØ¯ØŒ Ø­Ø°ÙØ´ Ú©Ù† Ùˆ Ø¨Ø±Ùˆ Ø³Ø±Ø§Øº Ø¨Ø¹Ø¯ÛŒ\n",
    "#         unique_ids.pop(0)\n",
    "#         continue\n",
    "\n",
    "#     # Ù…Ø±Ø­Ù„Ù‡ 5: Ú¯Ø±ÙØªÙ† Ø§ÙˆÙ„ÛŒÙ† Ø±Ø¯ÛŒÙ\n",
    "#     main_row = main_subset.iloc[0]\n",
    "#     main_ts = main_row['TimeStamp']\n",
    "#     main_value = main_row['Value']\n",
    "#     used_indices = [main_row.name]\n",
    "\n",
    "#     # Ù…Ø±Ø­Ù„Ù‡ 6: Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† TimeStamp Ø¨Ø±Ø§ÛŒ Ø³Ø§ÛŒØ± AssetIDÙ‡Ø§\n",
    "#     row_data = {'TimeStamp': main_ts, f'AssetID_{main_id}': main_value}\n",
    "\n",
    "#     for other_id in unique_ids[1:]:\n",
    "#         subset = df[df['AssetID'] == other_id].copy()\n",
    "#         if subset.empty:\n",
    "#             row_data[f'AssetID_{other_id}'] = np.nan\n",
    "#             continue\n",
    "\n",
    "#         subset['ts_diff'] = np.abs(subset['TimeStamp'] - main_ts)\n",
    "#         close_rows = subset[subset['ts_diff'] <= 1000]\n",
    "\n",
    "#         if not close_rows.empty:\n",
    "#             closest_row = close_rows.sort_values('ts_diff').iloc[0]\n",
    "#             row_data[f'AssetID_{other_id}'] = closest_row['Value']\n",
    "#             used_indices.append(closest_row.name)\n",
    "#         else:\n",
    "#             row_data[f'AssetID_{other_id}'] = np.nan\n",
    "\n",
    "#     # Ù…Ø±Ø­Ù„Ù‡ 7: Ø­Ø°Ù Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡â€ŒØ´Ø¯Ù‡\n",
    "#     df.drop(index=used_indices, inplace=True)\n",
    "\n",
    "#     # Ù…Ø±Ø­Ù„Ù‡ 8: Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ù‡ Ø®Ø±ÙˆØ¬ÛŒ\n",
    "#     output_df = pd.concat([output_df, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# # Ù†Ù…Ø§ÛŒØ´ Ø®Ø±ÙˆØ¬ÛŒ\n",
    "# print(output_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Ù…Ø±Ø­Ù„Ù‡ 1: Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ CSV\n",
    "# df = pd.read_csv('gen_brg_vib.csv')\n",
    "\n",
    "# # Ù…Ø±Ø­Ù„Ù‡ 2: Ø§Ø³ØªØ®Ø±Ø§Ø¬ AssetIDÙ‡Ø§ÛŒ ÛŒÚ©ØªØ§\n",
    "# unique_ids = df['AssetID'].unique().tolist()\n",
    "\n",
    "# # Ù…Ø±Ø­Ù„Ù‡ 3: Ø³Ø§Ø®Øª Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±\n",
    "# columns = ['TimeStamp'] + [f'AssetID_{uid}' for uid in unique_ids]\n",
    "# output_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# # Ù…Ø±Ø­Ù„Ù‡ 4 ØªØ§ 8: Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÚ©Ø±Ø§Ø±ÛŒ ØªØ§ Ø®Ø§Ù„ÛŒ Ø´Ø¯Ù† Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø§ØµÙ„ÛŒ\n",
    "# while not df.empty and unique_ids:\n",
    "#     main_id = unique_ids[0]\n",
    "#     main_subset = df[df['AssetID'] == main_id]\n",
    "\n",
    "#     if main_subset.empty:\n",
    "#         unique_ids.pop(0)\n",
    "#         continue\n",
    "\n",
    "#     # Ù…Ø±Ø­Ù„Ù‡ 5: Ú¯Ø±ÙØªÙ† Ø§ÙˆÙ„ÛŒÙ† Ø±Ø¯ÛŒÙ Ø§Ø² AssetID Ø§ØµÙ„ÛŒ\n",
    "#     main_row = main_subset.iloc[0]\n",
    "#     main_ts = main_row['TimeStamp']\n",
    "#     main_value = main_row['Value']\n",
    "#     used_indices = [main_row.name]\n",
    "\n",
    "#     # Ù…Ø±Ø­Ù„Ù‡ 6: Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† TimeStamp Ø¨Ø±Ø§ÛŒ Ø³Ø§ÛŒØ± AssetIDÙ‡Ø§\n",
    "#     row_data = {'TimeStamp': main_ts, f'AssetID_{main_id}': main_value}\n",
    "\n",
    "#     for other_id in unique_ids[1:]:\n",
    "#         subset = df[df['AssetID'] == other_id].copy()\n",
    "#         if subset.empty:\n",
    "#             row_data[f'AssetID_{other_id}'] = np.nan\n",
    "#             continue\n",
    "\n",
    "#         subset['ts_diff'] = np.abs(subset['TimeStamp'] - main_ts)\n",
    "#         close_rows = subset[subset['ts_diff'] <= 1000]\n",
    "\n",
    "#         if not close_rows.empty:\n",
    "#             closest_row = close_rows.sort_values('ts_diff').iloc[0]\n",
    "#             row_data[f'AssetID_{other_id}'] = closest_row['Value']\n",
    "#             used_indices.append(closest_row.name)\n",
    "#         else:\n",
    "#             row_data[f'AssetID_{other_id}'] = np.nan\n",
    "\n",
    "#     # Ù…Ø±Ø­Ù„Ù‡ 7: Ø­Ø°Ù Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡â€ŒØ´Ø¯Ù‡\n",
    "#     df.drop(index=used_indices, inplace=True)\n",
    "\n",
    "#     # Ù…Ø±Ø­Ù„Ù‡ 8: Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø±Ø¯ÛŒÙ Ø¬Ø¯ÛŒØ¯ Ø¨Ù‡ Ø®Ø±ÙˆØ¬ÛŒ\n",
    "#     output_df = pd.concat([output_df, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# # Ø°Ø®ÛŒØ±Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ø¯Ø± ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„\n",
    "# output_df.to_excel('output.xlsx', index=False)\n",
    "\n",
    "# print(\"âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯ Ùˆ Ø®Ø±ÙˆØ¬ÛŒ Ø¯Ø± ÙØ§ÛŒÙ„ output.xlsx Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pishva_r\\AppData\\Local\\Temp\\ipykernel_18224\\3662298117.py:52: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  output_df = pd.concat([output_df, pd.DataFrame([row_data])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯ØŒ Ø³ØªÙˆÙ† date Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯ØŒ Ùˆ Ø®Ø±ÙˆØ¬ÛŒ Ø¯Ø± ÙØ§ÛŒÙ„ output.xlsx Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ù…Ø±Ø­Ù„Ù‡ 1: Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ CSV\n",
    "df = pd.read_csv('dsas12_Lube Oil_8341_9287.csv')\n",
    "\n",
    "# Ù…Ø±Ø­Ù„Ù‡ 2: Ø§Ø³ØªØ®Ø±Ø§Ø¬ AssetIDÙ‡Ø§ÛŒ ÛŒÚ©ØªØ§\n",
    "unique_ids = df['AssetID'].unique().tolist()\n",
    "\n",
    "# Ù…Ø±Ø­Ù„Ù‡ 3: Ø³Ø§Ø®Øª Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±\n",
    "columns = ['TimeStamp'] + [f'AssetID_{uid}' for uid in unique_ids]\n",
    "output_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Ù…Ø±Ø­Ù„Ù‡ 4 ØªØ§ 8: Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÚ©Ø±Ø§Ø±ÛŒ ØªØ§ Ø®Ø§Ù„ÛŒ Ø´Ø¯Ù† Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø§ØµÙ„ÛŒ\n",
    "while not df.empty and unique_ids:\n",
    "    main_id = unique_ids[0]\n",
    "    main_subset = df[df['AssetID'] == main_id]\n",
    "\n",
    "    if main_subset.empty:\n",
    "        unique_ids.pop(0)\n",
    "        continue\n",
    "\n",
    "    # Ù…Ø±Ø­Ù„Ù‡ 5: Ú¯Ø±ÙØªÙ† Ø§ÙˆÙ„ÛŒÙ† Ø±Ø¯ÛŒÙ Ø§Ø² AssetID Ø§ØµÙ„ÛŒ\n",
    "    main_row = main_subset.iloc[0]\n",
    "    main_ts = main_row['TimeStamp']\n",
    "    main_value = main_row['Value']\n",
    "    used_indices = [main_row.name]\n",
    "\n",
    "    # Ù…Ø±Ø­Ù„Ù‡ 6: Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† TimeStamp Ø¨Ø±Ø§ÛŒ Ø³Ø§ÛŒØ± AssetIDÙ‡Ø§\n",
    "    row_data = {'TimeStamp': main_ts, f'AssetID_{main_id}': main_value}\n",
    "\n",
    "    for other_id in unique_ids[1:]:\n",
    "        subset = df[df['AssetID'] == other_id].copy()\n",
    "        if subset.empty:\n",
    "            row_data[f'AssetID_{other_id}'] = np.nan\n",
    "            continue\n",
    "\n",
    "        subset['ts_diff'] = np.abs(subset['TimeStamp'] - main_ts)\n",
    "        close_rows = subset[subset['ts_diff'] <= 1800]\n",
    "\n",
    "        if not close_rows.empty:\n",
    "            closest_row = close_rows.sort_values('ts_diff').iloc[0]\n",
    "            row_data[f'AssetID_{other_id}'] = closest_row['Value']\n",
    "            used_indices.append(closest_row.name)\n",
    "        else:\n",
    "            row_data[f'AssetID_{other_id}'] = np.nan\n",
    "\n",
    "    # Ù…Ø±Ø­Ù„Ù‡ 7: Ø­Ø°Ù Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡â€ŒØ´Ø¯Ù‡\n",
    "    df.drop(index=used_indices, inplace=True)\n",
    "\n",
    "    # Ù…Ø±Ø­Ù„Ù‡ 8: Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø±Ø¯ÛŒÙ Ø¬Ø¯ÛŒØ¯ Ø¨Ù‡ Ø®Ø±ÙˆØ¬ÛŒ\n",
    "    output_df = pd.concat([output_df, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Ù…Ø±Ø­Ù„Ù‡ Ù†Ù‡Ø§ÛŒÛŒ: ØªØ¨Ø¯ÛŒÙ„ TimeStamp Ø¨Ù‡ ØªØ§Ø±ÛŒØ® Ùˆ Ø²Ù…Ø§Ù† Ùˆ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø³ØªÙˆÙ† Ø¬Ø¯ÛŒØ¯\n",
    "output_df['date'] = pd.to_datetime(output_df['TimeStamp'], unit='s')\n",
    "output_df.drop(columns=['TimeStamp'], inplace=True)\n",
    "output_df.sort_values(by='date', inplace=True)\n",
    "\n",
    "\n",
    "# Ø°Ø®ÛŒØ±Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ø¯Ø± ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„\n",
    "output_df.to_excel('output_Lube_oil_g12.xlsx', index=False)\n",
    "\n",
    "print(\"âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯ØŒ Ø³ØªÙˆÙ† date Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯ØŒ Ùˆ Ø®Ø±ÙˆØ¬ÛŒ Ø¯Ø± ÙØ§ÛŒÙ„ output.xlsx Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¦ AssetID: 8341\n",
      "ID: 15217942\n",
      "Value: 0.07\n",
      "RecordTime: 04:24:53\n",
      "RecordDate: 2023/12/03\n",
      "DateTime: 2023-12-03 04:24:53\n",
      "TimeStamp: 1701564893\n",
      "ShiftCode: 11170153334483\n",
      "IsDeleted: False\n",
      "OutofRange: 1\n",
      "PersonelID: 91809\n",
      "Job: Operation\n",
      "MobileID: 24\n",
      "ValueType: 1\n",
      "OnTime: True\n",
      "\n",
      "ğŸ“¦ AssetID: 8342\n",
      "ID: 15217946\n",
      "Value: 12.1\n",
      "RecordTime: 04:25:19\n",
      "RecordDate: 2023/12/03\n",
      "DateTime: 2023-12-03 04:25:19\n",
      "TimeStamp: 1701564919\n",
      "ShiftCode: 11170153334483\n",
      "IsDeleted: False\n",
      "OutofRange: 1\n",
      "PersonelID: 91809\n",
      "Job: Operation\n",
      "MobileID: 24\n",
      "ValueType: 1\n",
      "OnTime: True\n",
      "\n",
      "ğŸ“¦ AssetID: 8343\n",
      "ID: 15217944\n",
      "Value: 69.0\n",
      "RecordTime: 04:24:56\n",
      "RecordDate: 2023/12/03\n",
      "DateTime: 2023-12-03 04:24:56\n",
      "TimeStamp: 1701564896\n",
      "ShiftCode: 11170153334483\n",
      "IsDeleted: False\n",
      "OutofRange: 1\n",
      "PersonelID: 91809\n",
      "Job: Operation\n",
      "MobileID: 24\n",
      "ValueType: 1\n",
      "OnTime: True\n",
      "\n",
      "ğŸ“¦ AssetID: 8344\n",
      "ID: 15217945\n",
      "Value: -240.0\n",
      "RecordTime: 04:25:08\n",
      "RecordDate: 2023/12/03\n",
      "DateTime: 2023-12-03 04:25:08\n",
      "TimeStamp: 1701564908\n",
      "ShiftCode: 11170153334483\n",
      "IsDeleted: False\n",
      "OutofRange: 1\n",
      "PersonelID: 91809\n",
      "Job: Operation\n",
      "MobileID: 24\n",
      "ValueType: 1\n",
      "OnTime: True\n",
      "\n",
      "ğŸ“¦ AssetID: 8346\n",
      "ID: 15217937\n",
      "Value: 6.9\n",
      "RecordTime: 04:24:37\n",
      "RecordDate: 2023/12/03\n",
      "DateTime: 2023-12-03 04:24:37\n",
      "TimeStamp: 1701564877\n",
      "ShiftCode: 11170153334483\n",
      "IsDeleted: False\n",
      "OutofRange: 1\n",
      "PersonelID: 91809\n",
      "Job: Operation\n",
      "MobileID: 24\n",
      "ValueType: 1\n",
      "OnTime: True\n",
      "\n",
      "ğŸ“¦ AssetID: 9286\n",
      "ID: 15217938\n",
      "Value: 7.2\n",
      "RecordTime: 04:24:39\n",
      "RecordDate: 2023/12/03\n",
      "DateTime: 2023-12-03 04:24:39\n",
      "TimeStamp: 1701564879\n",
      "ShiftCode: 11170153334483\n",
      "IsDeleted: False\n",
      "OutofRange: 1\n",
      "PersonelID: 91809\n",
      "Job: Operation\n",
      "MobileID: 24\n",
      "ValueType: 1\n",
      "OnTime: True\n",
      "\n",
      "ğŸ“¦ AssetID: 9287\n",
      "ID: 15217943\n",
      "Value: 1.28\n",
      "RecordTime: 04:24:55\n",
      "RecordDate: 2023/12/03\n",
      "DateTime: 2023-12-03 04:24:55\n",
      "TimeStamp: 1701564895\n",
      "ShiftCode: 11170153334483\n",
      "IsDeleted: False\n",
      "OutofRange: 1\n",
      "PersonelID: 91809\n",
      "Job: Operation\n",
      "MobileID: 24\n",
      "ValueType: 1\n",
      "OnTime: True\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "\n",
    "# Ø§ØªØµØ§Ù„ Ø¨Ù‡ SQL Server\n",
    "conn = pyodbc.connect(\n",
    "    'DRIVER={SQL Server};'\n",
    "    'SERVER=10WKS-PISHVA;'  # Ù†Ø§Ù… Ø³Ø±ÙˆØ± Ø·Ø¨Ù‚ ØªØµÙˆÛŒØ±\n",
    "    'DATABASE=PEGAH;'\n",
    "    'Trusted_Connection=yes;'\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Ù„ÛŒØ³Øª AssetIDÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø´Ù†\n",
    "asset_ids = [8341, 8342, 8343, 8344, 8346, 9286, 9287]\n",
    "\n",
    "# Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø¢Ø®Ø±ÛŒÙ† Ø±Ú©ÙˆØ±Ø¯ Ù‡Ø± AssetID\n",
    "latest_records = {}\n",
    "\n",
    "# Ø§Ø¬Ø±Ø§ÛŒ Ú©ÙˆØ¦Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± AssetID\n",
    "for asset_id in asset_ids:\n",
    "    query = f\"\"\"\n",
    "        SELECT TOP 1 *\n",
    "        FROM [PDA].[Periodic_Values]\n",
    "        WHERE UnitID = 11 AND AssetID = {asset_id}\n",
    "        ORDER BY DateTime DESC\n",
    "    \"\"\"\n",
    "    cursor.execute(query)\n",
    "    row = cursor.fetchone()\n",
    "    if row:\n",
    "        latest_records[asset_id] = row\n",
    "\n",
    "# Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬\n",
    "for asset_id, record in latest_records.items():\n",
    "    print(f\"\\nğŸ“¦ AssetID: {asset_id}\")\n",
    "    print(f\"ID: {record.ID}\")\n",
    "    print(f\"Value: {record.Value}\")\n",
    "    print(f\"RecordTime: {record.RecordTime}\")\n",
    "    print(f\"RecordDate: {record.RecordDate}\")\n",
    "    print(f\"DateTime: {record.DateTime}\")\n",
    "    print(f\"TimeStamp: {record.TimeStamp}\")\n",
    "    print(f\"ShiftCode: {record.ShiftCode}\")\n",
    "    print(f\"IsDeleted: {record.IsDeleted}\")\n",
    "    print(f\"OutofRange: {record.OutofRange}\")\n",
    "    print(f\"PersonelID: {record.PersonelID}\")\n",
    "    print(f\"Job: {record.Job}\")\n",
    "    print(f\"MobileID: {record.MobileID}\")\n",
    "    print(f\"ValueType: {record.ValueType}\")\n",
    "    print(f\"OnTime: {record.OnTime}\")\n",
    "\n",
    "# Ø¨Ø³ØªÙ† Ø§ØªØµØ§Ù„\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¢Ø®Ø±ÛŒÙ† Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ Ø¨Ø±Ø§ÛŒ UnitID=11:\n",
      "AssetID 8341 â†’ Value: 0.07\n",
      "AssetID 8342 â†’ Value: 12.1\n",
      "AssetID 8343 â†’ Value: 69.0\n",
      "AssetID 8344 â†’ Value: -240.0\n",
      "AssetID 8346 â†’ Value: 6.9\n",
      "AssetID 9286 â†’ Value: 7.2\n",
      "AssetID 9287 â†’ Value: 1.28\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "\n",
    "# Ø§ØªØµØ§Ù„ Ø¨Ù‡ SQL Server\n",
    "conn = pyodbc.connect(\n",
    "    'DRIVER={SQL Server};'\n",
    "    'SERVER=10WKS-PISHVA;'\n",
    "    'DATABASE=PEGAH;'\n",
    "    'Trusted_Connection=yes;'\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Ù„ÛŒØ³Øª AssetIDÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø´Ù†\n",
    "asset_ids = [8341, 8342, 8343, 8344, 8346, 9286, 9287]\n",
    "\n",
    "# Ù„ÛŒØ³Øª Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Value\n",
    "values = []\n",
    "\n",
    "# Ø§Ø¬Ø±Ø§ÛŒ Ú©ÙˆØ¦Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± AssetID Ùˆ Ø¯Ø±ÛŒØ§ÙØª ÙÙ‚Ø· Value\n",
    "for asset_id in asset_ids:\n",
    "    query = f\"\"\"\n",
    "        SELECT TOP 1 [Value]\n",
    "        FROM [PDA].[Periodic_Values]\n",
    "        WHERE UnitID = 11 AND AssetID = {asset_id}\n",
    "        ORDER BY DateTime DESC\n",
    "    \"\"\"\n",
    "    cursor.execute(query)\n",
    "    row = cursor.fetchone()\n",
    "    if row:\n",
    "        values.append(row.Value)\n",
    "    else:\n",
    "        values.append(None)  # Ø§Ú¯Ø± Ø±Ú©ÙˆØ±Ø¯ÛŒ Ù†Ø¨ÙˆØ¯ØŒ Ù…Ù‚Ø¯Ø§Ø± None Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù‡\n",
    "\n",
    "# Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯Ù† Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¯Ø± Û· Ù…ØªØºÛŒØ± Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡\n",
    "value_8341, value_8342, value_8343, value_8344, value_8346, value_9286, value_9287 = values\n",
    "\n",
    "# Ù†Ù…Ø§ÛŒØ´ Ù…Ù‚Ø§Ø¯ÛŒØ±\n",
    "print(\"âœ… Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¢Ø®Ø±ÛŒÙ† Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ Ø¨Ø±Ø§ÛŒ UnitID=11:\")\n",
    "print(f\"AssetID 8341 â†’ Value: {value_8341}\")\n",
    "print(f\"AssetID 8342 â†’ Value: {value_8342}\")\n",
    "print(f\"AssetID 8343 â†’ Value: {value_8343}\")\n",
    "print(f\"AssetID 8344 â†’ Value: {value_8344}\")\n",
    "print(f\"AssetID 8346 â†’ Value: {value_8346}\")\n",
    "print(f\"AssetID 9286 â†’ Value: {value_9286}\")\n",
    "print(f\"AssetID 9287 â†’ Value: {value_9287}\")\n",
    "\n",
    "# Ø¨Ø³ØªÙ† Ø§ØªØµØ§Ù„\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
